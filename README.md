# PRODIGY_GA_04
Image-to-Image Translation using Pix2Pix (Conditional GAN) as part of Prodigy Infotech Generative AI Internship â€“ Task 04.

## Image-to-Image Translation using Pix2Pix (cGAN)

This project implements **Image-to-Image Translation** using a **Conditional Generative Adversarial Network (cGAN)** known as **Pix2Pix**, as part of **Task-04** of the **Prodigy Infotech Generative AI Internship**.

---

## ğŸ” Task Objective
To learn and implement a Pix2Pix model that translates an input image into a corresponding output image by learning pixel-to-pixel mappings (for example: edges â†’ shoes).

---

## ğŸ§  Model Used
- **Pix2Pix (Conditional GAN)**
- Generator: U-Net
- Discriminator: PatchGAN
- Framework: **PyTorch**

---

## ğŸ“‚ Dataset
- **edges2shoes dataset**
- Contains paired images required for supervised image-to-image translation.

---

## âš™ï¸ Implementation Highlights
- Dataset preparation and alignment
- Generator and Discriminator initialization
- Adversarial + L1 loss functions
- Training loop with logging
- Model checkpoints and configuration setup

---

## ğŸš§ Execution Note
Due to **GPU and resource limitations on free cloud platforms**, full training and final image generation could not be completed successfully.  
However, the **complete Pix2Pix pipeline**, training configuration, and execution process have been correctly implemented and verified up to training initiation.

---

## ğŸ§ª Tools & Technologies
- Python
- PyTorch
- Google Colab
- Pix2Pix Architecture

---

## ğŸ“Œ Internship Track
**Prodigy Infotech â€“ Generative AI Internship**

---

## âœ¨ Author
**Arfa Anjum Shaik**
